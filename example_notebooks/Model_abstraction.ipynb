{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_abstraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmagannaDevelop/segnet/blob/mru_tests/example_notebooks/Model_abstraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHw_6M1yXu8b",
        "colab_type": "text"
      },
      "source": [
        "# MultiResUNet\n",
        "## DCI-Net\n",
        "#### Gustavo Magaña López\n",
        "\n",
        "Creación de una clase que facilite el entrenamiento serializado de las arquitecturas encontradas en DCI-NET/segmed.\n",
        "\n",
        "\\########################################################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7esbcDmCpM_",
        "colab_type": "code",
        "outputId": "780a52d2-8178-4147-ed50-7ff43c1ef67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYetdkI4C6bp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5acebf09-e6e6-4663-955c-7a80491a9679"
      },
      "source": [
        "dir()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Any',\n",
              " 'Callable',\n",
              " 'Dict',\n",
              " 'In',\n",
              " 'List',\n",
              " 'ModelCheckpoint',\n",
              " 'NoReturn',\n",
              " 'Optional',\n",
              " 'Out',\n",
              " 'ReduceLROnPlateau',\n",
              " 'SGD',\n",
              " 'Segmed',\n",
              " 'Tuple',\n",
              " 'Type',\n",
              " 'Union',\n",
              " '_',\n",
              " '_19',\n",
              " '_20',\n",
              " '_21',\n",
              " '_22',\n",
              " '_27',\n",
              " '_28',\n",
              " '_35',\n",
              " '_36',\n",
              " '_4',\n",
              " '_44',\n",
              " '_64',\n",
              " '_71',\n",
              " '__',\n",
              " '___',\n",
              " '__builtin__',\n",
              " '__builtins__',\n",
              " '__doc__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " '_dh',\n",
              " '_exit_code',\n",
              " '_i',\n",
              " '_i1',\n",
              " '_i10',\n",
              " '_i11',\n",
              " '_i12',\n",
              " '_i13',\n",
              " '_i14',\n",
              " '_i15',\n",
              " '_i16',\n",
              " '_i17',\n",
              " '_i18',\n",
              " '_i19',\n",
              " '_i2',\n",
              " '_i20',\n",
              " '_i21',\n",
              " '_i22',\n",
              " '_i23',\n",
              " '_i24',\n",
              " '_i25',\n",
              " '_i26',\n",
              " '_i27',\n",
              " '_i28',\n",
              " '_i29',\n",
              " '_i3',\n",
              " '_i30',\n",
              " '_i31',\n",
              " '_i32',\n",
              " '_i33',\n",
              " '_i34',\n",
              " '_i35',\n",
              " '_i36',\n",
              " '_i37',\n",
              " '_i38',\n",
              " '_i39',\n",
              " '_i4',\n",
              " '_i40',\n",
              " '_i41',\n",
              " '_i42',\n",
              " '_i43',\n",
              " '_i44',\n",
              " '_i45',\n",
              " '_i46',\n",
              " '_i47',\n",
              " '_i48',\n",
              " '_i49',\n",
              " '_i5',\n",
              " '_i50',\n",
              " '_i51',\n",
              " '_i52',\n",
              " '_i53',\n",
              " '_i54',\n",
              " '_i55',\n",
              " '_i56',\n",
              " '_i57',\n",
              " '_i58',\n",
              " '_i59',\n",
              " '_i6',\n",
              " '_i60',\n",
              " '_i61',\n",
              " '_i62',\n",
              " '_i63',\n",
              " '_i64',\n",
              " '_i65',\n",
              " '_i66',\n",
              " '_i67',\n",
              " '_i68',\n",
              " '_i69',\n",
              " '_i7',\n",
              " '_i70',\n",
              " '_i71',\n",
              " '_i72',\n",
              " '_i73',\n",
              " '_i74',\n",
              " '_i75',\n",
              " '_i76',\n",
              " '_i77',\n",
              " '_i78',\n",
              " '_i79',\n",
              " '_i8',\n",
              " '_i80',\n",
              " '_i81',\n",
              " '_i82',\n",
              " '_i9',\n",
              " '_ih',\n",
              " '_ii',\n",
              " '_iii',\n",
              " '_log_file',\n",
              " '_log_file_path',\n",
              " '_oh',\n",
              " '_sh',\n",
              " 'dataset_paths',\n",
              " 'datetime',\n",
              " 'drive',\n",
              " 'exit',\n",
              " 'files',\n",
              " 'get_ipython',\n",
              " 'glob',\n",
              " 'h5py',\n",
              " 'json',\n",
              " 'keras',\n",
              " 'models',\n",
              " 'mru',\n",
              " 'mru2',\n",
              " 'mru3',\n",
              " 'mts',\n",
              " 'my_compiling_kw',\n",
              " 'my_hyper_params',\n",
              " 'my_print',\n",
              " 'myp',\n",
              " 'np',\n",
              " 'optimizers',\n",
              " 'os',\n",
              " 'pd',\n",
              " 'platform',\n",
              " 'plt',\n",
              " 'psutil',\n",
              " 'quit',\n",
              " 're',\n",
              " 'root_dir',\n",
              " 'skio',\n",
              " 'sns',\n",
              " 'socket',\n",
              " 'sys',\n",
              " 'tf',\n",
              " 'timing',\n",
              " 'train_segnet',\n",
              " 'train_test_split',\n",
              " 'unet',\n",
              " 'uuid',\n",
              " 'x']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvwdXdIkfp0E",
        "colab_type": "code",
        "outputId": "809285b4-400f-4f65-9e19-e19960cee3a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "!apt install jq"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 65%\r\rReading package lists... 65%\r\rReading package lists... 66%\r\rReading package lists... 66%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 76%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "jq is already the newest version (1.5+dfsg-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUVhISDWOwT5",
        "colab_type": "code",
        "outputId": "1d515aad-6835-4f2e-eaa1-2f6e1490ab10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## If changes are made to the repo, uninstall and\n",
        "## a fresh pip install are required, so it seems.\n",
        "#!pip uninstall segnet\n",
        "!pip install git+https://github.com/gmagannaDevelop/segnet.git@mru_tests\n",
        "##!pip install git+https://github.com/gmagannaDevelop/segnet.git@log_hotfix"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/gmagannaDevelop/segnet.git@mru_tests\n",
            "  Cloning https://github.com/gmagannaDevelop/segnet.git (to revision mru_tests) to /tmp/pip-req-build-ykruxybb\n",
            "  Running command git clone -q https://github.com/gmagannaDevelop/segnet.git /tmp/pip-req-build-ykruxybb\n",
            "  Running command git checkout -b mru_tests --track origin/mru_tests\n",
            "  Switched to a new branch 'mru_tests'\n",
            "  Branch 'mru_tests' set up to track remote branch 'mru_tests' from 'origin'.\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.9.0)\n",
            "Collecting appdirs\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.8.1)\n",
            "Collecting astroid\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ae/86734823047962e7b8c8529186a1ac4a7ca19aaf1aa0c7713c022ef593fd/astroid-2.3.3-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: atomicwrites in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.3.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (19.3.0)\n",
            "Collecting black\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/bb/ad34bbc93d1bea3de086d7c59e528d4a503ac8fe318bd1fa48605584c3d2/black-19.10b0-py36-none-any.whl (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (7.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.10.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (4.4.1)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.2.2)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.1.8)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.8.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.4.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.4.0)\n",
            "Collecting isort\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.14.1)\n",
            "Requirement already satisfied: kiwisolver in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.1.0)\n",
            "Collecting lazy-object-proxy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/dd/b1e3407e9e6913cf178e506cd0dee818e58694d9a5cd1984e3f6a8b9a10f/lazy_object_proxy-1.4.3-cp36-cp36m-manylinux1_x86_64.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.1.2)\n",
            "Collecting mccabe\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (8.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.17.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (20.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.25.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (6.2.2)\n",
            "Requirement already satisfied: pluggy in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.7.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.10.0)\n",
            "Requirement already satisfied: py in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.8.1)\n",
            "Collecting pylint\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/59/43fc36c5ee316bb9aeb7cf5329cdbdca89e5749c34d5602753827c0aa2dc/pylint-2.4.4-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 19.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.4.6)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.6.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.6.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2018.9)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.1.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.13)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.22.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.4.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.1.0)\n",
            "Collecting toml\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/12/ced7105d2de62fa7c8fb5fce92cc4ce66b57c95fb875e9318dba7f8c5db0/toml-0.10.0-py2.py3-none-any.whl\n",
            "Collecting typed-ast\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/ed/5459080d95eb87a02fe860d447197be63b6e2b5e9ff73c2b0a85622994f4/typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 20.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.1.8)\n",
            "Requirement already satisfied: werkzeug in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.11.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.0.0)\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/34/fa/c5cc4f796eb954b56fd1f6c7c315647b18b027e0736c9ae87b73bbb1f933/pathspec-0.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from black->segnet==0.4) (2019.12.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver->segnet==0.4) (42.0.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (0.33.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (1.15.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (1.1.0)\n",
            "Building wheels for collected packages: segnet\n",
            "  Building wheel for segnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segnet: filename=segnet-0.4-cp36-none-any.whl size=28011 sha256=ee16ee97e6d32e08ae0fdc8a7c7829b07dc8304a40e44ce7e065ddbf7fb73f2a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oqyebenc/wheels/f1/c1/51/0ee27f445c3a618413714a84d4f5500547456389437a85a87f\n",
            "Successfully built segnet\n",
            "Installing collected packages: appdirs, lazy-object-proxy, typed-ast, astroid, toml, pathspec, black, isort, mccabe, pylint, segnet\n",
            "Successfully installed appdirs-1.4.3 astroid-2.3.3 black-19.10b0 isort-4.3.21 lazy-object-proxy-1.4.3 mccabe-0.6.1 pathspec-0.7.0 pylint-2.4.4 segnet-0.4 toml-0.10.0 typed-ast-1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCRoHPcGgvEL",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe9L3SCGqtJw",
        "colab_type": "code",
        "outputId": "1d15b4eb-003d-4a8f-cb88-a6fbd30cfc0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "!pip install gputil\n",
        "import GPUtil\n",
        "GPUtil.showUtilization(all=False, attrList=None, useOldCode=False)\n",
        "deviceIDs = GPUtil.getAvailable(order = 'first', limit = 1, maxLoad = 0.5, maxMemory = 0.5, includeNan=False, excludeID=[], excludeUUID=[])\n",
        "deviceIDs\n",
        "!pip install gpuinfo\n",
        "from gpuinfo import GPUInfo as gpu\n",
        "gpu.check_empty()\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n!pip install gputil\\nimport GPUtil\\nGPUtil.showUtilization(all=False, attrList=None, useOldCode=False)\\ndeviceIDs = GPUtil.getAvailable(order = 'first', limit = 1, maxLoad = 0.5, maxMemory = 0.5, includeNan=False, excludeID=[], excludeUUID=[])\\ndeviceIDs\\n!pip install gpuinfo\\nfrom gpuinfo import GPUInfo as gpu\\ngpu.check_empty()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxVrrV2VXLGA",
        "colab_type": "code",
        "outputId": "83a127cc-15d6-4848-9997-d4b703393fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "### System-related\n",
        "import platform,socket,re,uuid,json,psutil # for getSystemInfo method\n",
        "import sys\n",
        "import os\n",
        "import datetime \n",
        "from typing import Dict, Optional, List, Tuple, Any, NoReturn, Callable, Union, Type\n",
        "#import importlib.util\n",
        "###############################################################\n",
        "\n",
        "### Machine learning specific\n",
        "#import segmentation_models as sm\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras.models\n",
        "import tensorflow as tf\n",
        "###############################################################\n",
        "\n",
        "### In-Out\n",
        "from skimage import io as skio\n",
        "import json \n",
        "import pandas as pd\n",
        "import h5py\n",
        "import glob\n",
        "###############################################################\n",
        "\n",
        "### Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "###############################################################\n",
        "\n",
        "### Numerical\n",
        "import numpy as np\n",
        "###############################################################\n",
        "\n",
        "### Repo-specific (segnet)\n",
        "from segnet.train import train_segnet\n",
        "from segnet.models import unet\n",
        "from segnet.models import multiresunet as mru\n",
        "from segnet.models import multiresunet2 as mru2\n",
        "from segnet.models import multiresunet3 as mru3\n",
        "from segnet.utils import timing\n",
        "from segnet.metrics import metrics as mts\n",
        "#from segnet.segnet.train.train_segnet import train_segnet\n",
        "#import segnet.segnet as segnet\n",
        "\n",
        "### Data-related\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/')\n",
        "###############################################################\n",
        "\n",
        "\n",
        "### Not an import, but mandatory to be defined here :\n",
        "root_dir   = \"drive/My Drive/DCI-Net\"\n",
        "_log_file  = os.path.join(root_dir, \"time_logs.jsonl\")\n",
        "_log_file_path = \"drive/My Drive/DCI-Net/time_logs.jsonl\""
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pde_pTyigywK",
        "colab_type": "text"
      },
      "source": [
        "Class definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-odQDJK_js4",
        "colab_type": "text"
      },
      "source": [
        "# TODO :\n",
        "1. Set all default hyperparameters as class atributes to eliminate bloating of all methods.\n",
        "\n",
        "2. Create the comment logging system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQqkgQdAY6qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FINAL :\n",
        "class Segmed(object):\n",
        "  \"\"\"\n",
        "    Deep Learning Model Generator Object.\n",
        "  \"\"\"\n",
        "\n",
        "  # List of needed modules :\n",
        "  import platform,socket,re,uuid,json,psutil # for getSystemInfo method\n",
        "  import os\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.style.use(\"ggplot\")\n",
        "  import tensorflow as tf\n",
        "  from typing import Tuple, Optional, Union, Dict, Any, NoReturn\n",
        "  # End of needed modules\n",
        "\n",
        "  # Definition of static methods, utility functions logically\n",
        "  # related to the class, but not semantically.\n",
        "  @staticmethod\n",
        "  def assert_isdir(path: str) -> str:\n",
        "    \"\"\" Returns argument `path` if it is a directory, \n",
        "    raises an exception otherwise.   \n",
        "    \"\"\"\n",
        "    if os.path.isdir(path):\n",
        "      return path\n",
        "    else:\n",
        "      raise Exception(f\"Path '{path}' is not a directory.\")\n",
        "  \n",
        "  @staticmethod\n",
        "  def ls(path: str) -> List[str]:\n",
        "    \"\"\" Wrapper for os.listdir(path) \"\"\"\n",
        "    return os.listdir(path)\n",
        "\n",
        "  @staticmethod\n",
        "  def assert_isfile(path: str) -> str:\n",
        "    \"\"\" Docstring \"\"\"\n",
        "    if os.path.isfile(path):\n",
        "      return path\n",
        "    else:\n",
        "      raise Exception(f\"File '{path}' is not a regular file.\")    \n",
        "\n",
        "  @staticmethod\n",
        "  def json_cast(x: Any) -> Union[str,Any]:\n",
        "    \"\"\" ~Verify (via good 'ol duck-typing) if an object is JSON-serialisable~\n",
        "    \n",
        "    Returns :\n",
        "          x,  if parameter `x` is JSON-serialisable, \n",
        "    \n",
        "      str(x), if json.dumps(x) throws an exception.\n",
        "    \"\"\"\n",
        "    if timing.is_jsonable(x):\n",
        "      return x\n",
        "    else:\n",
        "      return str(x)\n",
        "\n",
        "  def _getSystemInfo() -> Dict[str,str]:\n",
        "    \"\"\" Get SystemInfo as a dictionary.\n",
        "    Original code snippet can be found at :\n",
        "    https://stackoverflow.com/questions/3103178/how-to-get-the-system-info-with-python \n",
        "    \"\"\"\n",
        "    try:\n",
        "      info={}\n",
        "      info['platform']=platform.system()\n",
        "      info['platform-release']=platform.release()\n",
        "      info['platform-version']=platform.version()\n",
        "      info['architecture']=platform.machine()\n",
        "      info['hostname']=socket.gethostname()\n",
        "      info['processor']=platform.processor()\n",
        "      info['ram']=str(round(psutil.virtual_memory().total / (1024.0 **3)))+\" GB\"\n",
        "      return info\n",
        "    except Exception as e:\n",
        "      logging.exception(e)\n",
        "  # End of static methods definition.\n",
        "\n",
        "  # Class attributes which will be used if necessary parameters are \n",
        "  # not passed to different methods.\n",
        "  # Decided to use dict literals instead of the constructor because of this :\n",
        "  # \n",
        "  __data_gen_args: Dict[str,Any] = {\n",
        "      \"rescale\": 1.0 / 255.0,\n",
        "      \"validation_split\": 0.2,\n",
        "      \"dtype\": tf.float32,\n",
        "  }\n",
        "\n",
        "  __hyper_params: Dict[str,Any] = {\n",
        "      \"batch_size\": 8,\n",
        "      \"epochs\": 10,\n",
        "      \"steps_per_epoch\": 10\n",
        "  }\n",
        "\n",
        "  __model_checkpoint_kw: Dict[str,Any] = {\n",
        "      \"monitor\": \"val_jaccard_index\", \n",
        "      \"verbose\": 1, \n",
        "      \"save_best_only\": True, \n",
        "      \"mode\": \"max\"\n",
        "  }\n",
        "\n",
        "  __compiling_kw: Dict[str,Any] = {\n",
        "      \"loss\": tf.keras.losses.binary_crossentropy,\n",
        "      \"optimizer\": tf.keras.optimizers.Adam(),\n",
        "      \"metrics\": [\n",
        "        mts.jaccard_index, mts.dice_coef, \n",
        "        mts.O_Rate, mts.U_Rate, mts.Err_rate\n",
        "      ]\n",
        "  }\n",
        "  # End of class attributes.\n",
        "\n",
        "  def __init__(\n",
        "      self, \n",
        "      model: tf.keras.Model,\n",
        "      name: str,\n",
        "      base_dir: str,\n",
        "      data_path: str,\n",
        "      author: str,\n",
        "      seed: int = 1\n",
        "  ) -> None:\n",
        "    # Set instance attributes :\n",
        "    ## Identifiers :\n",
        "    self._model: tf.keras.Model = model\n",
        "    self.__datetime: datetime.datetime = datetime.datetime.utcnow()\n",
        "    self._date: str = str(self.__datetime).split(\".\")[0]\n",
        "    self._name: str = name\n",
        "    self._author: str = author\n",
        "    ## Directories :\n",
        "    ### Model :\n",
        "    self._base_dir: str = self.assert_isdir(base_dir)\n",
        "    self._instance_dir: str = os.path.join(self._base_dir, self.name)\n",
        "    ### Data :\n",
        "    self._data_path: str = self.assert_isdir(data_path)\n",
        "    self._img_path: str = os.path.join(self._data_path, 'imgs')\n",
        "    self._msks_path: str = os.path.join(self._data_path, 'msks')\n",
        "    \n",
        "    self.__seed: int = seed\n",
        "\n",
        "    ## Create model directory :\n",
        "    try:\n",
        "      os.mkdir(self._instance_dir)\n",
        "    except:\n",
        "      raise Exception(f\"Could not create directory `{self._instance_dir}` at `{self._base_dir}`\")\n",
        "\n",
        "    try:\n",
        "      def __custom_print_to_summary_file(x):\n",
        "        with open(self.summary_file, 'a') as f:\n",
        "          f.write(f\"{x}\\n\")\n",
        "      self._model.summary(print_fn=__custom_print_to_summary_file)\n",
        "    except:\n",
        "      raise Exception(f\"Could not dump `model.summary()` output to {self.summary_file}\")\n",
        "    \n",
        "    ## Create an instance decorator, specifying _log_file_path\n",
        "    self.__logged: Callable = timing.time_log(self.log_file)\n",
        "    \n",
        "    ## Decorate __compile method\n",
        "    self.__compile: Callable = self.__logged(self.__compile)\n",
        "    _initial_message = f\"\\n{self._author}, running '{self._name}' model instantiated at {self._date}\"\n",
        "    _initial_message += f\" on system with specs :\\n {json.dumps(self.system_info)}\\n\\n\"\n",
        "    with open(self.comment_file, \"w\") as f:\n",
        "      f.write(_initial_message)\n",
        "\n",
        "  def __getitem__(self, key):\n",
        "    try:\n",
        "      return getattr(self, f\"_{key}\")\n",
        "    except AttributeError:\n",
        "      print(f\"Attribute `{key}` is not yet defined for this object (or does not exist)\")\n",
        "      print(f\"Defined attributes are: {self.keys}\")\n",
        "\n",
        "  @property\n",
        "  def methods(self) -> List[str]:\n",
        "    \"\"\" \"\"\"\n",
        "    return [func for func in dir(self) if callable(getattr(self, func))]\n",
        "\n",
        "  @property\n",
        "  def keys(self) -> List[Any]:\n",
        "    \"\"\" Get the keys (as a list) that can be used to index the Segmed object \"\"\"\n",
        "    return sorted(list(map(lambda x: x[1:], self.__dict__.keys())))\n",
        "\n",
        "  @property\n",
        "  def items(self) -> Dict[str,Any]:\n",
        "    \"\"\" Get the items `{ key: value }` pairs oh the class. \"\"\"\n",
        "    return { key: self[key] for key in self.keys }\n",
        "\n",
        "  @property\n",
        "  def values(self) -> List[Any]:\n",
        "    \"\"\" Get the values, i.e. object properties. \"\"\" \n",
        "    return [ self[key] for key in self.keys ]\n",
        "\n",
        "  @property\n",
        "  def name(self) -> str:\n",
        "    \"\"\" Name of the model, composed of: name-(author)-(date) \"\"\"\n",
        "    return f\"{self._name}-({self._author})-({self._date})\"\n",
        "\n",
        "  @property\n",
        "  def snapshot_file(self) -> str:\n",
        "    \"\"\" Name (full path) of the model snapshot file (model weights, .h5 format) \"\"\"\n",
        "    return os.path.join(self._instance_dir, f\"{self.name}-model.h5\")\n",
        "\n",
        "  @property\n",
        "  def history_file(self) -> str:\n",
        "    \"\"\" Name (full path) of the training history file (.csv format) \"\"\"\n",
        "    return os.path.join(self._instance_dir, f\"{self.name}-history.csv\")\n",
        "\n",
        "  @property\n",
        "  def comment_file(self) -> str:\n",
        "    \"\"\" Name (full path) of the comment file (.txt format) \"\"\"\n",
        "    return os.path.join(self._instance_dir, f\"{self.name}-comments.txt\")\n",
        "\n",
        "  @property\n",
        "  def log_file(self) -> str:\n",
        "    \"\"\" Name (full path) of the log file (.jsonl format) \"\"\"\n",
        "    return os.path.join(self._instance_dir, f\"{self.name}-function_calls.jsonl\")\n",
        "\n",
        "  @property\n",
        "  def summary_file(self) -> str:\n",
        "    \"\"\" Name (full path) of the summary file, \n",
        "    yielded by calling self._model.summary() \n",
        "    (.txt format) \n",
        "    \"\"\"\n",
        "    return os.path.join(self._instance_dir, f\"{self.name}-summary.txt\")\n",
        "\n",
        "  @property\n",
        "  def model_file(self) -> str:\n",
        "    \"\"\"  \"\"\"\n",
        "\n",
        "  @property\n",
        "  def images_path(self) -> str:\n",
        "    \"\"\" Path where images are stored. \n",
        "    Following the Keras convention it should contain a\n",
        "    directory named `images`.\n",
        "    \"\"\"\n",
        "    return self._img_path\n",
        "\n",
        "  @property\n",
        "  def masks_path(self) -> str:\n",
        "    \"\"\" Path where segmentation masks are stored. \n",
        "    Following the Keras convention it should contain a\n",
        "    directory named `masks`.\n",
        "    \"\"\"\n",
        "    return self._msks_path\n",
        "\n",
        "  @property\n",
        "  def images(self) -> List[str]:\n",
        "    \"\"\" A list of all the images contained in `self.images_path`/images/ \"\"\"\n",
        "    return self.ls(os.path.join(self.images_path, 'images'))\n",
        "\n",
        "  @property\n",
        "  def masks(self) -> List[str]:\n",
        "    \"\"\" A list of all the segmentation masks contained in `self.masks_path`/masks/ \"\"\"\n",
        "    return self.ls(os.path.join(self.masks_path, 'masks'))\n",
        "\n",
        "  @property\n",
        "  def system_info(self) -> Dict[str,str]:\n",
        "    \"\"\" Wrapper for Segmed._getSystemInfo \"\"\"\n",
        "    return Segmed._getSystemInfo()\n",
        "\n",
        "  def create_train_test_generators(\n",
        "      self, \n",
        "      data_gen_args: Optional[Dict[str, Any]] = None,\n",
        "      hyper_params: Optional[Dict[str, Any]] =  None\n",
        "  ) -> NoReturn:\n",
        "    \"\"\" Generate the train/test split. \n",
        "      data_gen_args defaults to the following Dict :\n",
        "        {\n",
        "          \"rescale\": 1.0 / 255.0,\n",
        "          \"validation_split\": 0.2,\n",
        "          \"dtype\": tf.float32,\n",
        "        }\n",
        "    \"\"\"\n",
        "    \n",
        "    self._data_gen_args: Dict[str,Any] = data_gen_args or Segmed.__data_gen_args\n",
        "    self._hyper_params:  Dict[str,Any] = hyper_params  or Segmed.__hyper_params\n",
        "\n",
        "    # Crea the training generators with the defined transformations\n",
        "    self.__image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**self._data_gen_args)\n",
        "    self.__mask_datagen  = tf.keras.preprocessing.image.ImageDataGenerator(**self._data_gen_args)\n",
        "    \n",
        "    # Decoreate the ImageDataGenerator.flow from directory method for logging.\n",
        "    _img_gen = self.__logged(self.__image_datagen.flow_from_directory)\n",
        "    # Take images from directories\n",
        "    self._image_generator_train = _img_gen(\n",
        "        self._img_path,\n",
        "        class_mode=None,\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=self._hyper_params[\"batch_size\"],\n",
        "        seed=self.__seed,\n",
        "        subset=\"training\",\n",
        "    )\n",
        "    \n",
        "    _msk_gen = self.__logged(self.__mask_datagen.flow_from_directory)\n",
        "    self._mask_generator_train = _msk_gen(\n",
        "        self._msks_path,\n",
        "        class_mode=None,\n",
        "        color_mode=\"grayscale\",\n",
        "        batch_size=self._hyper_params[\"batch_size\"],\n",
        "        seed=self.__seed,\n",
        "        subset=\"training\",\n",
        "    )\n",
        "    # Combine both generators\n",
        "    # This needs to be a generator of generators, see the following\n",
        "    # https://github.com/tensorflow/tensorflow/issues/32357\n",
        "    self._train_generator = (\n",
        "        pair for pair in zip(self._image_generator_train, self._mask_generator_train)\n",
        "    )\n",
        "\n",
        "    # And now the validation generators\n",
        "    self._image_generator_val = _img_gen(\n",
        "        self._img_path,\n",
        "        class_mode=None,\n",
        "        color_mode=\"rgb\",\n",
        "        batch_size=self._hyper_params[\"batch_size\"],\n",
        "        seed=self.__seed,\n",
        "        subset=\"validation\",\n",
        "    )\n",
        "\n",
        "    self._mask_generator_val = _msk_gen(\n",
        "        self._msks_path,\n",
        "        class_mode=None,\n",
        "        color_mode=\"grayscale\",\n",
        "        batch_size=self._hyper_params[\"batch_size\"],\n",
        "        seed=self.__seed,\n",
        "        subset=\"validation\",\n",
        "    )\n",
        "\n",
        "    # Combine both generators, with same issue as before\n",
        "    self._val_generator = (\n",
        "        pair for pair in zip(self._image_generator_val, self._mask_generator_val)\n",
        "    )\n",
        "\n",
        "  def show_img_and_mask(self, n: int = 5) -> NoReturn:\n",
        "    \"\"\" Show `n` images and segmentation maps, side by side\n",
        "    to verify that they are batched together.\n",
        "    \"\"\"\n",
        "    for i, pair in zip(range(n), self._train_generator):\n",
        "      plt.figure(0)\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.imshow(pair[0][0, ...])\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.imshow(pair[1][0, ..., 0])\n",
        "      plt.show()\n",
        "\n",
        "    \n",
        "  def create_custom_callback(\n",
        "      self, \n",
        "      model_checkpoint_kw: Optional[Dict[str,Any]] = None\n",
        "  ) -> NoReturn:\n",
        "    \"\"\" Define the checkpoint callback.\n",
        "      Parameters (keyword arguments) used to call \n",
        "      `tf.keras.callbacks.ModelCheckpoint()` can be \n",
        "      specified as a dictionary (parameter `model_checkpoint_kw`).\n",
        "\n",
        "      Parameters:\n",
        "        model_checkpoint_kw : Optional, defaults to:\n",
        "          Dict( \n",
        "            monitor=monitor, \n",
        "            verbose=1, \n",
        "            save_best_only=True, \n",
        "            mode=\"max\"\n",
        "          )\n",
        "    \"\"\"\n",
        "    # Define the checkpoint callback, always maximum mode for custom metrics\n",
        "    self._model_checkpoint_kw: Dict[str,Any] = model_checkpoint_kw or Segmed.__model_checkpoint_kw\n",
        "      \n",
        "    self._checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        self.snapshot_file, \n",
        "        **self._model_checkpoint_kw\n",
        "    )\n",
        "    \n",
        "  def compile(\n",
        "      self,\n",
        "      compiling_kw: Optional[Dict[str,Any]] = None\n",
        "  ) -> NoReturn:\n",
        "    \"\"\" This eventually will be a wrapper \"\"\" \n",
        "\n",
        "    self._compiling_kw: Dict[str,Any] = compiling_kw or Segmed.__compiling_kw \n",
        "    self.__compile(**self._compiling_kw)\n",
        "\n",
        "  def __compile(self, **compiling_kw):\n",
        "    \"\"\" Compile the model with custom params, \n",
        "    creating a log \n",
        "    \"\"\"\n",
        "    self._model.compile(**compiling_kw)\n",
        "\n",
        "  def train(\n",
        "      self, \n",
        "      compiling_kw: Dict[str,Any] = None,\n",
        "      model_checkpoint_kw: Optional[Dict[str,Any]] = None,\n",
        "      data_gen_args: Optional[Dict[str, Any]] = None,\n",
        "      hyper_params: Optional[Dict[str, Any]] =  None\n",
        "  ) -> NoReturn:\n",
        "    \"\"\" Docstring \"\"\"\n",
        "\n",
        "    self._compiling_kw:  Dict[str,Any] = compiling_kw  or Segmed.__compiling_kw\n",
        "    self._data_gen_args: Dict[str,Any] = data_gen_args or Segmed.__data_gen_args\n",
        "    self._hyper_params:  Dict[str,Any] = hyper_params  or Segmed.__hyper_params \n",
        "    self._model_checkpoint_kw: Dict[str,Any] = model_checkpoint_kw or Segmed.__model_checkpoint_kw\n",
        "\n",
        "    self.compile(compiling_kw=compiling_kw)\n",
        "    self.create_custom_callback(model_checkpoint_kw=model_checkpoint_kw)\n",
        "    self.create_train_test_generators(data_gen_args=data_gen_args, hyper_params=hyper_params)\n",
        "    \n",
        "    # Decorate the model's fit generator to log parameters and execution time :\n",
        "    _fit_generator = self.__logged(self._model.fit_generator)\n",
        "\n",
        "    # Create history \n",
        "    self._history = _fit_generator(\n",
        "        self._train_generator,\n",
        "        callbacks=[self._checkpoint],\n",
        "        verbose=1,\n",
        "        validation_data=self._val_generator,\n",
        "        validation_steps=self._hyper_params[\"steps_per_epoch\"],\n",
        "        steps_per_epoch=self._hyper_params[\"steps_per_epoch\"],\n",
        "        epochs=self._hyper_params[\"epochs\"],\n",
        "        use_multiprocessing=True\n",
        "    )\n",
        "\n",
        "    try:\n",
        "      self._metrics_history = pd.DataFrame(self._history.history)\n",
        "      self._metrics_history.to_csv(self.history_file)\n",
        "      print(f\"History saved to {self.history_file}\")\n",
        "    except:\n",
        "      print(f\"Could not open file : {self.history_file}\")\n",
        "\n",
        "  def comment(self, cmt: str) -> NoReturn:\n",
        "    \"\"\" Comment something \"\"\"\n",
        "    _now = str(datetime.datetime.utcnow()).split(\".\")[0]\n",
        "    _cmt = f\"\\n{self._author} @ {_now} : \\n\\t{cmt}\"\n",
        "    with open(self.comment_file, 'a') as f:\n",
        "      f.write(f\"{_cmt} \\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nls_wv6HNqTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_paths = {\n",
        "    \"isbi\": \"drive/My Drive/DCI-Net/Colab_data/ISBI_neural/structured\", # Images as tiff volumes\n",
        "    \"colonoscopy\": \"drive/My Drive/DCI-Net/Colab_data/colonoscopy\",     # Full original\n",
        "    \"dermoscopy80\": \"drive/My Drive/DCI-Net/Colab_data/dermoscopy80\",   # reduced to 80 images\n",
        "    \"dermoscopy150\": \"drive/My Drive/DCI-Net/Colab_data/dermoscopy150\", # reduced to 150, randomly \n",
        "                                                                          # sampled images.\n",
        "    \"chinese1\": \"drive/My Drive/DCI-Net/Colab_data/Dataset 2\"           # Chinese dataset, Abdiel's\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsF_v4RXbmMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizers = {\n",
        "    \"chinese\": tf.keras.optimizers.SGD(learning_rate=0.06, momentum=0.2, nesterov=False),\n",
        "    \"Original Adam\": tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.999, epsilon=10e-8)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWHEkWNdkhG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "3ad73397-8472-4511-8cf9-81ebc678c909"
      },
      "source": [
        "optimizers[\"Original Adam\"].get_config()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amsgrad': False,\n",
              " 'beta_1': 0.9,\n",
              " 'beta_2': 0.999,\n",
              " 'decay': 0.0,\n",
              " 'epsilon': 1e-07,\n",
              " 'learning_rate': 0.001,\n",
              " 'name': 'Adam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBC-Y2kHz8Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_compiling_kw = {\n",
        "    'optimizer': optimizers[\"Original Adam\"],\n",
        "    'loss': 'binary_crossentropy',\n",
        "    'metrics': [\n",
        "      mts.jaccard_index, mts.dice_coef, \n",
        "      mts.O_Rate, mts.U_Rate, mts.Err_rate \n",
        "    ]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktT7280909G3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_hyper_params = {\n",
        "    'batch_size': 25,\n",
        "    'epochs': 150,\n",
        "    'steps_per_epoch': 6\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr4D7CyxlC3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = {\n",
        "    \"Unet\": unet(),\n",
        "    \"MultiResUNet Edwin\": mru.MultiResUnet(),\n",
        "    \"MultiResUNet Gustavo\": mru2.MultiResUNet(),\n",
        "    \"MultiResUNet Original\": mru3.MultiResUnet()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrQz9DmqnUJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a446f55-56a6-48de-db40-963252435fde"
      },
      "source": [
        "models[\"MultiResUNet Gustavo\"]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.training.Model at 0x7f0c55ba01d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SougBZf0TkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_print(x, file_path='test.txt'):\n",
        "  with open(file_path, 'a') as f:\n",
        "    f.write(f\"{x}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uOGAph1l_Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models[\"MultiResUNet Gustavo\"].summary(print_fn=my_print)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL8TscH10zKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea93bd5d-6518-45ef-9b63-d65e8a114f4c"
      },
      "source": [
        "!du -h test.txt"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52K\ttest.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMLn73P3Gb0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Segmed(\n",
        "    model=mru2.MultiResUNet(),  # Instantiated from segmed.models.multiresunet\n",
        "    name='MultiResU-Net 2',       # Self-explanatory\n",
        "    base_dir=os.path.join(root_dir, \"SegMedLogs\"), # Where should the model file (.h5) is to be saved\n",
        "    data_path=dataset_paths[\"chinese1\"], # See dataset_paths to analise the dataset.\n",
        "    author='Gustavo Magaña'\n",
        ") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uwY3DUBacpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.comment(\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzHO4Ov733e8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.comment(\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejkhyPRTbvHA",
        "colab_type": "code",
        "outputId": "a7d386ec-1818-4ac6-98cb-2750e904d1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        }
      },
      "source": [
        "x.train(compiling_kw=my_compiling_kw, hyper_params=my_hyper_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Found 80 images belonging to 1 classes.\n",
            "Found 80 images belonging to 1 classes.\n",
            "Found 20 images belonging to 1 classes.\n",
            "Found 20 images belonging to 1 classes.\n",
            "Epoch 1/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2e43234de6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiling_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_compiling_kw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_hyper_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-89ab2d361a74>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, compiling_kw, model_checkpoint_kw, data_gen_args, hyper_params)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"steps_per_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/segnet/utils/timing.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mexec_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mte\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[25,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/SGD/gradients/gradients/zeros_136}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/mul/_931]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[25,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/SGD/gradients/gradients/zeros_136}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abAusnL6ajtW",
        "colab_type": "code",
        "outputId": "af60676c-0916-42fd-e4e9-d56ce8c2636c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "x.create_train_test_generators()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 64 images belonging to 1 classes.\n",
            "Found 64 images belonging to 1 classes.\n",
            "Found 16 images belonging to 1 classes.\n",
            "Found 16 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsoe4Y65HMao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from types import FunctionType"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XgmKdeXH33R",
        "colab_type": "code",
        "outputId": "451584ea-448d-49fc-c0a6-97d01ba373cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "x.__dict__.items()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('_model', <tensorflow.python.keras.engine.training.Model object at 0x7fec25f71c88>), ('_Segmed__datetime', datetime.datetime(2020, 1, 29, 6, 57, 19, 720278)), ('_date', '2020-01-29 06:57:19'), ('_name', 'multiresunet'), ('_snapshot_dir', 'drive/My Drive/DCI-Net/ModelSnapshots'), ('_history_dir', 'drive/My Drive/DCI-Net/Historiae'), ('_comment_dir', 'drive/My Drive/DCI-Net/Comments'), ('_data_path', 'drive/My Drive/DCI-Net/Colab_data/dermoscopy80'), ('_log_file_path', 'drive/My Drive/DCI-Net/time_logs.jsonl'), ('_img_path', 'drive/My Drive/DCI-Net/Colab_data/dermoscopy80/imgs'), ('_msks_path', 'drive/My Drive/DCI-Net/Colab_data/dermoscopy80/msks'), ('_Segmed__seed', 1), ('_author', 'Gustavo Magaña'), ('_Segmed__logged', <function time_log.<locals>.timed at 0x7fec2b8e9b70>), ('_Segmed__compile', <function Segmed.__compile at 0x7fec2b8e91e0>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYIzK0MUFxUL",
        "colab_type": "code",
        "outputId": "14d5bc6c-0a0b-46fc-d11f-5adaac089ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[f for f, y in x.__dict__.items() if isinstance(y, FunctionType)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Segmed__logged', '_Segmed__compile']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BAvvej8umjd",
        "colab_type": "code",
        "outputId": "c2ccf8e6-2c3f-4254-8493-28e22e5e9d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "x.train(hyper_params=hyper_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 64 images belonging to 1 classes.\n",
            "Found 64 images belonging to 1 classes.\n",
            "Found 16 images belonging to 1 classes.\n",
            "Found 16 images belonging to 1 classes.\n",
            "Epoch 1/80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAocgP6aDR_B",
        "colab_type": "code",
        "outputId": "4a8d85c1-3f08-4fea-fac3-05c714e105db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "x.create_train_test_generators()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 489 images belonging to 1 classes.\n",
            "Found 489 images belonging to 1 classes.\n",
            "Found 122 images belonging to 1 classes.\n",
            "Found 122 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADJjPqus46bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.comment(\"fresh start\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC5wVrDQ7gBd",
        "colab_type": "code",
        "outputId": "4a2d3f0b-7d8d-49cf-b504-147682dd20a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "!ls -t \"drive/My Drive/DCI-Net/Comments/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'multiresunet-(Gustavo Magaña)-(2020-01-29 07:18:39).txt'\n",
            "'multiresunet-(Gustavo Magaña)-(2020-01-29 07:13:23).txt'\n",
            "'multiresunet-(Gustavo Magaña)-(2020-01-29 06:38:59).txt'\n",
            "'multiresunet-(Gustavo Magaña)-(2020-01-29 06:18:12).txt'\n",
            "'multiresunet-(Gustavo Magaña)-(2020-01-29 06:16:09).txt'\n",
            "'multiresunet-(Gustavo Magaña)-(2020-01-29 06:12:09).txt'\n",
            "'multiresunet-(Gustavo Magaña)-(2020-01-29 04:11:56).txt'\n",
            "'multiresunet-(Gustavo Magaña)-(2020-01-29 04:11:09).txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJLxVz5if8nZ",
        "colab_type": "code",
        "outputId": "59f7ab95-0cf1-4c6e-f605-27ec0869fdcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!cat \"drive/My Drive/DCI-Net/Comments/multiresunet-(Gustavo Magaña)-(2020-01-29 07:18:39).txt\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Gustavo Magaña, running 'multiresunet' model instantiated at 2020-01-29 07:18:39on system with specs :\n",
            " {'platform': 'Linux', 'platform-release': '4.14.137+', 'platform-version': '#1 SMP Thu Aug 8 02:47:02 PDT 2019', 'architecture': 'x86_64', 'hostname': '2b5d4a3808d4', 'processor': 'x86_64', 'ram': '13 GB'}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFxWeJDK6Qm0",
        "colab_type": "code",
        "outputId": "618bded4-eb7d-4fb0-ae5e-6b21624cec4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 80 images belonging to 1 classes.\n",
            "Found 80 images belonging to 1 classes.\n",
            "Found 20 images belonging to 1 classes.\n",
            "Found 20 images belonging to 1 classes.\n",
            "Epoch 1/10\n",
            " 9/10 [==========================>...] - ETA: 2s - loss: 0.5697 - jaccard_index: 0.2266 - dice_coef: 0.3674 - O_Rate: 0.0057 - U_Rate: 0.0682 - Err_rate: 0.2820Epoch 1/10\n",
            "10/10 [==============================] - 4s 387ms/step - loss: 0.8121 - jaccard_index: 0.1390 - dice_coef: 0.2438 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00001: val_jaccard_index improved from -inf to 0.13901, saving model to drive/My Drive/DCI-Net/ModelSnapshots/multiresunet-(Gustavo Magaña)-(2020-01-28 19:45:06).h5\n",
            "10/10 [==============================] - 84s 8s/step - loss: 0.5613 - jaccard_index: 0.2313 - dice_coef: 0.3736 - O_Rate: 0.0051 - U_Rate: 0.0666 - Err_rate: 0.2628 - val_loss: 0.8121 - val_jaccard_index: 0.1390 - val_dice_coef: 0.2438 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "Epoch 2/10\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4882 - jaccard_index: 0.2638 - dice_coef: 0.4169 - O_Rate: 7.2584e-05 - U_Rate: 0.0621 - Err_rate: 0.1295Epoch 1/10\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.6509 - jaccard_index: 0.1387 - dice_coef: 0.2434 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00002: val_jaccard_index did not improve from 0.13901\n",
            "10/10 [==============================] - 7s 705ms/step - loss: 0.4876 - jaccard_index: 0.2650 - dice_coef: 0.4184 - O_Rate: 6.5325e-05 - U_Rate: 0.0623 - Err_rate: 0.1297 - val_loss: 0.6509 - val_jaccard_index: 0.1387 - val_dice_coef: 0.2434 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "Epoch 3/10\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4814 - jaccard_index: 0.2665 - dice_coef: 0.4200 - O_Rate: 3.6239e-05 - U_Rate: 0.0627 - Err_rate: 0.1287Epoch 1/10\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 0.6069 - jaccard_index: 0.1390 - dice_coef: 0.2439 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00003: val_jaccard_index improved from 0.13901 to 0.13904, saving model to drive/My Drive/DCI-Net/ModelSnapshots/multiresunet-(Gustavo Magaña)-(2020-01-28 19:45:06).h5\n",
            "10/10 [==============================] - 9s 859ms/step - loss: 0.4803 - jaccard_index: 0.2675 - dice_coef: 0.4212 - O_Rate: 3.2615e-05 - U_Rate: 0.0629 - Err_rate: 0.1290 - val_loss: 0.6069 - val_jaccard_index: 0.1390 - val_dice_coef: 0.2439 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "Epoch 4/10\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4767 - jaccard_index: 0.2673 - dice_coef: 0.4213 - O_Rate: 1.1494e-05 - U_Rate: 0.0613 - Err_rate: 0.1220Epoch 1/10\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.5927 - jaccard_index: 0.1379 - dice_coef: 0.2422 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00004: val_jaccard_index did not improve from 0.13904\n",
            "10/10 [==============================] - 7s 704ms/step - loss: 0.4762 - jaccard_index: 0.2672 - dice_coef: 0.4212 - O_Rate: 1.0345e-05 - U_Rate: 0.0619 - Err_rate: 0.1240 - val_loss: 0.5927 - val_jaccard_index: 0.1379 - val_dice_coef: 0.2422 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "Epoch 5/10\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4703 - jaccard_index: 0.2739 - dice_coef: 0.4298 - O_Rate: 6.5111e-06 - U_Rate: 0.0647 - Err_rate: 0.1345Epoch 1/10\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 0.5826 - jaccard_index: 0.1383 - dice_coef: 0.2428 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00005: val_jaccard_index did not improve from 0.13904\n",
            "10/10 [==============================] - 7s 713ms/step - loss: 0.4711 - jaccard_index: 0.2727 - dice_coef: 0.4283 - O_Rate: 9.9062e-06 - U_Rate: 0.0652 - Err_rate: 0.1366 - val_loss: 0.5826 - val_jaccard_index: 0.1383 - val_dice_coef: 0.2428 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "Epoch 6/10\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4701 - jaccard_index: 0.2667 - dice_coef: 0.4205 - O_Rate: 8.8151e-06 - U_Rate: 0.0655 - Err_rate: 0.1391Epoch 1/10\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.5776 - jaccard_index: 0.1381 - dice_coef: 0.2425 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00006: val_jaccard_index did not improve from 0.13904\n",
            "10/10 [==============================] - 7s 709ms/step - loss: 0.4680 - jaccard_index: 0.2708 - dice_coef: 0.4255 - O_Rate: 9.8061e-06 - U_Rate: 0.0648 - Err_rate: 0.1362 - val_loss: 0.5776 - val_jaccard_index: 0.1381 - val_dice_coef: 0.2425 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "Epoch 7/10\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4636 - jaccard_index: 0.2737 - dice_coef: 0.4293 - O_Rate: 9.7850e-06 - U_Rate: 0.0656 - Err_rate: 0.1417Epoch 1/10\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 0.5804 - jaccard_index: 0.1438 - dice_coef: 0.2511 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00007: val_jaccard_index improved from 0.13904 to 0.14375, saving model to drive/My Drive/DCI-Net/ModelSnapshots/multiresunet-(Gustavo Magaña)-(2020-01-28 19:45:06).h5\n",
            "10/10 [==============================] - 9s 885ms/step - loss: 0.4634 - jaccard_index: 0.2739 - dice_coef: 0.4295 - O_Rate: 8.8065e-06 - U_Rate: 0.0654 - Err_rate: 0.1404 - val_loss: 0.5804 - val_jaccard_index: 0.1438 - val_dice_coef: 0.2511 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "Epoch 8/10\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4609 - jaccard_index: 0.2770 - dice_coef: 0.4331 - O_Rate: 1.5592e-05 - U_Rate: 0.0672 - Err_rate: 0.1493Epoch 1/10\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 0.5717 - jaccard_index: 0.1377 - dice_coef: 0.2418 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00008: val_jaccard_index did not improve from 0.14375\n",
            "10/10 [==============================] - 7s 725ms/step - loss: 0.4607 - jaccard_index: 0.2749 - dice_coef: 0.4306 - O_Rate: 1.5340e-05 - U_Rate: 0.0660 - Err_rate: 0.1443 - val_loss: 0.5717 - val_jaccard_index: 0.1377 - val_dice_coef: 0.2418 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "Epoch 9/10\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4560 - jaccard_index: 0.2732 - dice_coef: 0.4289 - O_Rate: 1.7400e-05 - U_Rate: 0.0627 - Err_rate: 0.1269Epoch 1/10\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 0.5687 - jaccard_index: 0.1382 - dice_coef: 0.2426 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00009: val_jaccard_index did not improve from 0.14375\n",
            "10/10 [==============================] - 7s 718ms/step - loss: 0.4561 - jaccard_index: 0.2744 - dice_coef: 0.4304 - O_Rate: 1.7841e-05 - U_Rate: 0.0635 - Err_rate: 0.1307 - val_loss: 0.5687 - val_jaccard_index: 0.1382 - val_dice_coef: 0.2426 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "Epoch 10/10\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4535 - jaccard_index: 0.2763 - dice_coef: 0.4327 - O_Rate: 8.0670e-06 - U_Rate: 0.0661 - Err_rate: 0.1419Epoch 1/10\n",
            "10/10 [==============================] - 1s 137ms/step - loss: 0.5672 - jaccard_index: 0.1372 - dice_coef: 0.2411 - O_Rate: 62914376.0000 - U_Rate: 0.0000e+00 - Err_rate: 62914376.0000\n",
            "\n",
            "Epoch 00010: val_jaccard_index did not improve from 0.14375\n",
            "10/10 [==============================] - 7s 735ms/step - loss: 0.4522 - jaccard_index: 0.2781 - dice_coef: 0.4348 - O_Rate: 7.8023e-06 - U_Rate: 0.0655 - Err_rate: 0.1393 - val_loss: 0.5672 - val_jaccard_index: 0.1372 - val_dice_coef: 0.2411 - val_O_Rate: 62914376.0000 - val_U_Rate: 0.0000e+00 - val_Err_rate: 62914376.0000\n",
            "History saved to drive/My Drive/DCI-Net/Historiae/multiresunet-(Gustavo Magaña)-(2020-01-28 19:45:06).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXhBG-r86AhR",
        "colab_type": "code",
        "outputId": "b88f5d70-5894-492f-ae9a-e5fe3c361880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "dir(x[\"history\"])\n",
        "x[\"history\"].params"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': None,\n",
              " 'do_validation': True,\n",
              " 'epochs': 10,\n",
              " 'metrics': ['loss',\n",
              "  'jaccard_index',\n",
              "  'dice_coef',\n",
              "  'O_Rate',\n",
              "  'U_Rate',\n",
              "  'Err_rate',\n",
              "  'val_loss',\n",
              "  'val_jaccard_index',\n",
              "  'val_dice_coef',\n",
              "  'val_O_Rate',\n",
              "  'val_U_Rate',\n",
              "  'val_Err_rate'],\n",
              " 'samples': 10,\n",
              " 'steps': 10,\n",
              " 'verbose': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJWjlxLkW9lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare the paths to use (following the Keras convention)\n",
        "# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\n",
        "\n",
        "_model_log_path = os.path.join(\n",
        "    _model_snapshots_dir, \n",
        "    yield_model_name(architecture=\"MultiResUNet\")\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtl5hSO9nAZ2",
        "colab_type": "text"
      },
      "source": [
        "Get the stored snapshots :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Wbszp9Ofbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}