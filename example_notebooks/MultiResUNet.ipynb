{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiResUNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmagannaDevelop/segnet/blob/mru_tests/example_notebooks/MultiResUNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHw_6M1yXu8b",
        "colab_type": "text"
      },
      "source": [
        "# MultiResUNet\n",
        "## DCI-Net\n",
        "### Primera Implementación\n",
        "#### Gustavo Magaña\n",
        "\n",
        "\\########################################################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7esbcDmCpM_",
        "colab_type": "code",
        "outputId": "7c4bb574-613b-4f67-f367-716d718e0c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUVhISDWOwT5",
        "colab_type": "code",
        "outputId": "19755096-2c0c-44d2-918e-82c3b08cb922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## If changes are made to the repo, uninstall and\n",
        "## a fresh pip install are required, so it seems.\n",
        "#!pip uninstall segnet\n",
        "!pip install git+https://github.com/gmagannaDevelop/segnet.git@mru_tests"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/gmagannaDevelop/segnet.git@mru_tests\n",
            "  Cloning https://github.com/gmagannaDevelop/segnet.git (to revision mru_tests) to /tmp/pip-req-build-l0e6bgvi\n",
            "  Running command git clone -q https://github.com/gmagannaDevelop/segnet.git /tmp/pip-req-build-l0e6bgvi\n",
            "  Running command git checkout -b mru_tests --track origin/mru_tests\n",
            "  Switched to a new branch 'mru_tests'\n",
            "  Branch 'mru_tests' set up to track remote branch 'mru_tests' from 'origin'.\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.8.1)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.4.3)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.8.0)\n",
            "Requirement already satisfied: astroid in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.3.2)\n",
            "Requirement already satisfied: atomicwrites in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.3.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (19.3.0)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (19.3b0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (7.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.10.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (4.4.0)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.2.2)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.1.7)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.8.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.4.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.23)\n",
            "Requirement already satisfied: isort in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (4.3.21)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.14.0)\n",
            "Requirement already satisfied: kiwisolver in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.1.0)\n",
            "Requirement already satisfied: lazy-object-proxy in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.4.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.1.1)\n",
            "Requirement already satisfied: mccabe in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.6.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (7.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.17.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (19.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (4.3.0)\n",
            "Requirement already satisfied: pluggy in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.7.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.10.0)\n",
            "Requirement already satisfied: py in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.8.0)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.4.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.4.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.6.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2.6.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (2018.9)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.1.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (3.13)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.21.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.3.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.1.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.10.0)\n",
            "Requirement already satisfied: typed-ast in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.1.7)\n",
            "Requirement already satisfied: werkzeug in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (1.11.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.6/dist-packages (from segnet==0.4) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver->segnet==0.4) (41.4.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->segnet==0.4) (0.46)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->segnet==0.4) (1.15.1)\n",
            "Building wheels for collected packages: segnet\n",
            "  Building wheel for segnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segnet: filename=segnet-0.4-cp36-none-any.whl size=22786 sha256=c7099eb437cdf0d152d20d3d5b94a9027f079467f24d96fb05df325ca3ac90a4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n4vn7l85/wheels/f1/c1/51/0ee27f445c3a618413714a84d4f5500547456389437a85a87f\n",
            "Successfully built segnet\n",
            "Installing collected packages: segnet\n",
            "Successfully installed segnet-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxVrrV2VXLGA",
        "colab_type": "code",
        "outputId": "3a4a4b59-59e5-4b97-dc26-de6ab31ddddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "### System-related\n",
        "import sys\n",
        "import os\n",
        "#import importlib.util\n",
        "###############################################################\n",
        "\n",
        "### Machine learning specific\n",
        "#import segmentation_models as sm\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "###############################################################\n",
        "\n",
        "### In-Out\n",
        "from skimage import io\n",
        "import glob\n",
        "###############################################################\n",
        "\n",
        "### Numerical\n",
        "import numpy as np\n",
        "###############################################################\n",
        "\n",
        "### Repo-specific (segnet)\n",
        "from segnet.train import train_segnet\n",
        "from segnet.models import multiresunet2 as mru\n",
        "#from segnet.segnet.train.train_segnet import train_segnet\n",
        "#import segnet.segnet as segnet\n",
        "\n",
        "### Data-related\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "###############################################################"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pRrtgcrDThX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6d6adcd7-5371-4583-8bd9-fe3acfdcd62d"
      },
      "source": [
        "!ls \"drive/My Drive/DCI-Net/\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoints  Data\t\t multiresunet.py  Snippets\n",
            "Colab_data   MultiResUNet.ipynb  __pycache__\t  timing.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce2TEroWZ2WI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "737b496e-dc50-47b7-e5e4-6e9321963bf2"
      },
      "source": [
        "!ls \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images\tmasks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Ah1NY_NX2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0db7a340-6cb9-463b-ecfb-1bab1ac6636b"
      },
      "source": [
        "# Define some example hyperparameters\n",
        "batch_size = 8\n",
        "epochs = 50\n",
        "steps_per_epoch=100\n",
        "\n",
        "# Declare the paths to use (following the Keras convention)\n",
        "# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\n",
        "root_dir   = \"drive/My Drive/DCI-Net/\"\n",
        "data_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\n",
        "img_path   = os.path.join(data_path, 'images')\n",
        "masks_path = os.path.join(data_path, 'masks')\n",
        "model_file = os.path.join(root_dir, 'first_mutlires.h5')\n",
        "\n",
        "# Instantiate a MultiResUNet model :\n",
        "model = mru.MultiResUNet()\n",
        "\n",
        "# Train the model!\n",
        "history = train_segnet.train_segnet(\n",
        "    model,\n",
        "    img_path,\n",
        "    masks_path,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    model_file=model_file,\n",
        ")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00001: val_jaccard_index improved from -inf to 1.00000, saving model to drive/My Drive/DCI-Net/first_mutlires.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py:676: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  logs[k] = self.totals[k] / self.seen\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 77s 766ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 2/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00002: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 67ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 3/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00003: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 64ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 4/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00004: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 5/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00005: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 6/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00006: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 66ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 7/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00007: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 60ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 8/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00008: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 64ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 9/50\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00009: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 10/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00010: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 64ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 11/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00011: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 64ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 12/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00012: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 68ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 13/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00013: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 14/50\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00014: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 15/50\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00015: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 60ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 16/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00016: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 64ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 17/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00017: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 18/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00018: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 61ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 19/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00019: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 68ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 20/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00020: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 67ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 21/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00021: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 64ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 22/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00022: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 23/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00023: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 61ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 24/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00024: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 70ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 25/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00025: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 73ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 26/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00026: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 67ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 27/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00027: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 65ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 28/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00028: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 59ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 29/50\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00029: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 57ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 30/50\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00030: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 57ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 31/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00031: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 65ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 32/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00032: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 33/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00033: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 61ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 34/50\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00034: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 61ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 35/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00035: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 63ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 36/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00036: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 63ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 37/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00037: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 61ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 38/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00038: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 67ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 39/50\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00039: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 66ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 40/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00040: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 60ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 41/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00041: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 42/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00042: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 43/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00043: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 71ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 44/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00044: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 75ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 45/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00045: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 69ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 46/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00046: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 68ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 47/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00047: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 62ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 48/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00048: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 64ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 49/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00049: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 6s 59ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n",
            "Epoch 50/50\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000Epoch 1/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0000e+00 - jaccard_index: 1.0000 - dice_coef: 1.0000\n",
            "\n",
            "Epoch 00050: val_jaccard_index did not improve from 1.00000\n",
            "100/100 [==============================] - 7s 67ms/step - loss: nan - jaccard_index: 1.0000 - dice_coef: 1.0000 - val_loss: 0.0000e+00 - val_jaccard_index: 1.0000 - val_dice_coef: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPtPk3dFsO7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp time_logs.jsonl drive/My\\ Drive/DCI-Net/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaMlOM9rZQ1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd361499-7c70-4ff8-ed6b-189ce7574cbb"
      },
      "source": [
        "locals()[]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'In': ['',\n",
              "  \"get_ipython().system('ls')\",\n",
              "  \"get_ipython().system('pip install git+https://github.com/gmagannaDevelop/segnet.git@mru_tests')\",\n",
              "  \"import sys\\nimport os\\n#import importlib.util\\n###############################################################\\n\\n### Machine learning specific\\n#import segmentation_models as sm\\nfrom keras.optimizers import SGD\\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\\nfrom sklearn.model_selection import train_test_split\\n###############################################################\\n\\n### In-Out\\nfrom skimage import io\\nimport glob\\n###############################################################\\n\\n### Numerical\\nimport numpy as np\\n###############################################################\\n\\n### Repo-specific (segnet)\\nfrom segnet.train import train_segnet\\nfrom segnet.models import multiresunet2 as mru\\n#from segnet.segnet.train.train_segnet import train_segnet\\n#import segnet.segnet as segnet\\n\\n### Data-related\\nfrom google.colab import drive\\ndrive.mount('/content/drive/')\\n###############################################################\",\n",
              "  'get_ipython().system(\\'ls \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\')',\n",
              "  'get_ipython().system(\\'ls \"drive/My Drive/DCI-Net/\"\\')',\n",
              "  'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)',\n",
              "  'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\n\"\"\"\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n\"\"\"\" ',\n",
              "  'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\n\"\"\"\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n\"\"\" ',\n",
              "  'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\nhistory = train_segnet.train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)',\n",
              "  \"get_ipython().magic('ls ')\",\n",
              "  \"get_ipython().system('cp time_logs.jsonl drive/My\\\\\\\\ Drive/DCI-Net/')\",\n",
              "  'locals()'],\n",
              " 'ModelCheckpoint': keras.callbacks.ModelCheckpoint,\n",
              " 'Out': {8: '\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n'},\n",
              " 'ReduceLROnPlateau': keras.callbacks.ReduceLROnPlateau,\n",
              " 'SGD': keras.optimizers.SGD,\n",
              " '_': '\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n',\n",
              " '_8': '\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n',\n",
              " '__': '',\n",
              " '___': '',\n",
              " '__builtin__': <module 'builtins' (built-in)>,\n",
              " '__builtins__': <module 'builtins' (built-in)>,\n",
              " '__doc__': 'Automatically created module for IPython interactive environment',\n",
              " '__loader__': None,\n",
              " '__name__': '__main__',\n",
              " '__package__': None,\n",
              " '__spec__': None,\n",
              " '_dh': ['/content'],\n",
              " '_exit_code': 0,\n",
              " '_i': '!cp time_logs.jsonl drive/My\\\\ Drive/DCI-Net/',\n",
              " '_i1': '!ls',\n",
              " '_i10': 'ls',\n",
              " '_i11': '!cp time_logs.jsonl drive/My\\\\ Drive/DCI-Net/',\n",
              " '_i12': 'locals()',\n",
              " '_i2': '!pip install git+https://github.com/gmagannaDevelop/segnet.git@mru_tests',\n",
              " '_i3': \"import sys\\nimport os\\n#import importlib.util\\n###############################################################\\n\\n### Machine learning specific\\n#import segmentation_models as sm\\nfrom keras.optimizers import SGD\\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\\nfrom sklearn.model_selection import train_test_split\\n###############################################################\\n\\n### In-Out\\nfrom skimage import io\\nimport glob\\n###############################################################\\n\\n### Numerical\\nimport numpy as np\\n###############################################################\\n\\n### Repo-specific (segnet)\\nfrom segnet.train import train_segnet\\nfrom segnet.models import multiresunet2 as mru\\n#from segnet.segnet.train.train_segnet import train_segnet\\n#import segnet.segnet as segnet\\n\\n### Data-related\\nfrom google.colab import drive\\ndrive.mount('/content/drive/')\\n###############################################################\",\n",
              " '_i4': '!ls \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"',\n",
              " '_i5': '!ls \"drive/My Drive/DCI-Net/\"',\n",
              " '_i6': 'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)',\n",
              " '_i7': 'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\n\"\"\"\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n\"\"\"\" ',\n",
              " '_i8': 'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\n\"\"\"\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n\"\"\" ',\n",
              " '_i9': 'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\nhistory = train_segnet.train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)',\n",
              " '_ih': ['',\n",
              "  \"get_ipython().system('ls')\",\n",
              "  \"get_ipython().system('pip install git+https://github.com/gmagannaDevelop/segnet.git@mru_tests')\",\n",
              "  \"import sys\\nimport os\\n#import importlib.util\\n###############################################################\\n\\n### Machine learning specific\\n#import segmentation_models as sm\\nfrom keras.optimizers import SGD\\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\\nfrom sklearn.model_selection import train_test_split\\n###############################################################\\n\\n### In-Out\\nfrom skimage import io\\nimport glob\\n###############################################################\\n\\n### Numerical\\nimport numpy as np\\n###############################################################\\n\\n### Repo-specific (segnet)\\nfrom segnet.train import train_segnet\\nfrom segnet.models import multiresunet2 as mru\\n#from segnet.segnet.train.train_segnet import train_segnet\\n#import segnet.segnet as segnet\\n\\n### Data-related\\nfrom google.colab import drive\\ndrive.mount('/content/drive/')\\n###############################################################\",\n",
              "  'get_ipython().system(\\'ls \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\')',\n",
              "  'get_ipython().system(\\'ls \"drive/My Drive/DCI-Net/\"\\')',\n",
              "  'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)',\n",
              "  'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\n\"\"\"\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n\"\"\"\" ',\n",
              "  'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\n\"\"\"\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n\"\"\" ',\n",
              "  'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\nhistory = train_segnet.train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)',\n",
              "  \"get_ipython().magic('ls ')\",\n",
              "  \"get_ipython().system('cp time_logs.jsonl drive/My\\\\\\\\ Drive/DCI-Net/')\",\n",
              "  'locals()'],\n",
              " '_ii': 'ls',\n",
              " '_iii': 'batch_size = 8\\nepochs = 50\\nsteps_per_epoch=100\\n\\n# Declare the paths to use (following the Keras convention)\\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\\nroot_dir   = \"drive/My Drive/DCI-Net/\"\\ndata_path  = \"drive/My Drive/DCI-Net/Colab_data/Dataset 1\"\\nimg_path   = os.path.join(data_path, \\'images\\')\\nmasks_path = os.path.join(data_path, \\'masks\\')\\nmodel_file = os.path.join(root_dir, \\'first_mutlires.h5\\')\\n\\n# Instantiate a MultiResUNet model :\\nmodel = mru.MultiResUNet()\\n\\n# Train the model!\\nhistory = train_segnet.train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)',\n",
              " '_oh': {8: '\\nhistory = train_segnet(\\n    model,\\n    img_path,\\n    masks_path,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    steps_per_epoch=steps_per_epoch,\\n    model_file=model_file,\\n)\\n'},\n",
              " '_sh': <module 'IPython.core.shadowns' from '/usr/local/lib/python3.6/dist-packages/IPython/core/shadowns.py'>,\n",
              " 'batch_size': 8,\n",
              " 'data_path': 'drive/My Drive/DCI-Net/Colab_data/Dataset 1',\n",
              " 'drive': <module 'google.colab.drive' from '/usr/local/lib/python3.6/dist-packages/google/colab/drive.py'>,\n",
              " 'epochs': 50,\n",
              " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7f72633bc3c8>,\n",
              " 'get_ipython': <bound method InteractiveShell.get_ipython of <google.colab._shell.Shell object at 0x7f7265e36128>>,\n",
              " 'glob': <module 'glob' from '/usr/lib/python3.6/glob.py'>,\n",
              " 'history': <tensorflow.python.keras.callbacks.History at 0x7f7226e90400>,\n",
              " 'img_path': 'drive/My Drive/DCI-Net/Colab_data/Dataset 1/images',\n",
              " 'io': <module 'skimage.io' from '/usr/local/lib/python3.6/dist-packages/skimage/io/__init__.py'>,\n",
              " 'masks_path': 'drive/My Drive/DCI-Net/Colab_data/Dataset 1/masks',\n",
              " 'model': <tensorflow.python.keras.engine.training.Model at 0x7f72287dae10>,\n",
              " 'model_file': 'drive/My Drive/DCI-Net/first_mutlires.h5',\n",
              " 'mru': <module 'segnet.models.multiresunet2' from '/usr/local/lib/python3.6/dist-packages/segnet/models/multiresunet2.py'>,\n",
              " 'np': <module 'numpy' from '/usr/local/lib/python3.6/dist-packages/numpy/__init__.py'>,\n",
              " 'os': <module 'os' from '/usr/lib/python3.6/os.py'>,\n",
              " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7f72633bc3c8>,\n",
              " 'root_dir': 'drive/My Drive/DCI-Net/',\n",
              " 'steps_per_epoch': 100,\n",
              " 'sys': <module 'sys' (built-in)>,\n",
              " 'train_segnet': <module 'segnet.train.train_segnet' from '/usr/local/lib/python3.6/dist-packages/segnet/train/train_segnet.py'>,\n",
              " 'train_test_split': <function sklearn.model_selection._split.train_test_split>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNoGLM2BrvUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}